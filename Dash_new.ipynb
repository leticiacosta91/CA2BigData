{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9d0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark import SparkConf\n",
    "\n",
    "#Hadoop\n",
    "from hdfs import InsecureClient\n",
    "\n",
    "#Spark SQL functions\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import from_utc_timestamp, udf, array_distinct, col, when\n",
    "from pyspark.sql.functions import regexp_replace, year, month, dayofmonth, hour, format_string\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# Spark Datatypes\n",
    "from pyspark.sql.types import StringType, TimestampType, DateType, IntegerType\n",
    "from pyspark.sql.types import DoubleType, StructType, FloatType, StructField\n",
    "\n",
    "\n",
    "#Pandas\n",
    "import pandas as pd\n",
    "import json\n",
    "import emoji\n",
    "import stylecloud\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f0371ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppressing the warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe36ba70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/17 22:49:12 WARN Utils: Your hostname, muhammad-Vm resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "24/05/17 22:49:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/17 22:49:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/17 22:49:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark_conf = SparkConf().setMaster(\"local[*]\").setAppName(\"Tweets_Hadoop\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=spark_conf).config('spark.sql.session.timeZone', 'UTC').getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e2bf4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_salvo = spark.read.parquet(\"hdfs://localhost:9000/CA2BD/sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f80dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_fc_df = df_salvo.withColumn('sentiment',when(col(\"score\") > 0, '1').otherwise('0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0503c90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- clean_tweet: string (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      " |-- textblob: float (nullable = true)\n",
      " |-- vader: float (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- sentiment: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_fc_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48dc4b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                                                               |tokens                                                                                                                                                                |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|I HAVE TO SAY IT. ZAC EFRON IS MY DREAM BOY! OK I SAID IT                                                                                          |[i, have, to, say, it., zac, efron, is, my, dream, boy!, ok, i, said, it]                                                                                             |\n",
      "|@csbseal i have hes cute.  what do you think of the talk of them being DONE after this?people over reacting, reading too much into things?         |[@csbseal, i, have, hes, cute., , what, do, you, think, of, the, talk, of, them, being, done, after, this?people, over, reacting,, reading, too, much, into, things?] |\n",
      "|what happend??                                                                                                                                     |[what, happend??]                                                                                                                                                     |\n",
      "|but i am not the person who will wait around. i move on. throw lemons ma way and ill make lemonade                                                 |[but, i, am, not, the, person, who, will, wait, around., i, move, on., throw, lemons, ma, way, and, ill, make, lemonade]                                              |\n",
      "|@thecomagirlI declare this the summer of Vegan Handmade Giveaways! Stay tuned!  YAY!  I love Vegan Handmade Giveaways!!                            |[@thecomagirli, declare, this, the, summer, of, vegan, handmade, giveaways!, stay, tuned!, , yay!, , i, love, vegan, handmade, giveaways!!]                           |\n",
      "|God dammit!!! My ting tings cd is scratched!!!                                                                                                     |[god, dammit!!!, my, ting, tings, cd, is, scratched!!!]                                                                                                               |\n",
      "|@casperhe01  I'm in town now. I'll probably take my part next week. See you soon.                                                                  |[@casperhe01, , i'm, in, town, now., i'll, probably, take, my, part, next, week., see, you, soon.]                                                                    |\n",
      "|@zebedeejane cannot possibly believe it!                                                                                                           |[@zebedeejane, cannot, possibly, believe, it!]                                                                                                                        |\n",
      "|Headed to wild wings and jammin out to no rain by blind melon with @farrelljenkins, @jamierussell, anna &amp; joyce!                               |[headed, to, wild, wings, and, jammin, out, to, no, rain, by, blind, melon, with, @farrelljenkins,, @jamierussell,, anna, &amp;, joyce!]                              |\n",
      "|Jeff Turner: @abiteofsanity that's probably the same look I had when first read your Twitter bio.  http://superfeedr.com/entries/312d0 ...         |[jeff, turner:, @abiteofsanity, that's, probably, the, same, look, i, had, when, first, read, your, twitter, bio., , http://superfeedr.com/entries/312d0, ...]        |\n",
      "|@AtomicOvermind If only I could have interrupted you in the middle of that last tweet....                                                          |[@atomicovermind, if, only, i, could, have, interrupted, you, in, the, middle, of, that, last, tweet....]                                                             |\n",
      "|http://twitpic.com/6th0e - Me, myself and I.                                                                                                       |[http://twitpic.com/6th0e, -, me,, myself, and, i.]                                                                                                                   |\n",
      "|@djtechnasty Get 100 followers a day using www.tweeteradder.com Once you add everyone you are on the train or pay vip                              |[@djtechnasty, get, 100, followers, a, day, using, www.tweeteradder.com, once, you, add, everyone, you, are, on, the, train, or, pay, vip]                            |\n",
      "|@BeckyBlackhall yeah up is good laugh  enjoy Ur time                                                                                               |[@beckyblackhall, yeah, up, is, good, laugh, , enjoy, ur, time]                                                                                                       |\n",
      "|gonna hit the shower.                                                                                                                              |[gonna, hit, the, shower.]                                                                                                                                            |\n",
      "|@primaryposition should be until about 11am  then i have a few meetings                                                                            |[@primaryposition, should, be, until, about, 11am, , then, i, have, a, few, meetings]                                                                                 |\n",
      "|@behelzebub You move onto Web until it refreshes                                                                                                   |[@behelzebub, you, move, onto, web, until, it, refreshes]                                                                                                             |\n",
      "|@Jennifalconer oh and don't think i ever said thanks for the follow. Thank you!  x                                                                 |[@jennifalconer, oh, and, don't, think, i, ever, said, thanks, for, the, follow., thank, you!, , x]                                                                   |\n",
      "|@alexarox well, thank you...i have to recommend you new movie &quot;Ghosts of Girlfriends Past&quot; with Jennifer Garner and Matthew McConaughey  |[@alexarox, well,, thank, you...i, have, to, recommend, you, new, movie, &quot;ghosts, of, girlfriends, past&quot;, with, jennifer, garner, and, matthew, mcconaughey]|\n",
      "|@kopigao ooh okay metalheads are sooo rare in SG. especially female ones                                                                           |[@kopigao, ooh, okay, metalheads, are, sooo, rare, in, sg., especially, female, ones]                                                                                 |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.sql import SparkSession\n",
    "# Inicializar o Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "\n",
    "# Aplicar a tokenização no DataFrame\n",
    "tweets_fc_df_tokenized = tokenizer.transform(tweets_fc_df)\n",
    "\n",
    "# Exibir o resultado\n",
    "tweets_fc_df_tokenized.select(\"text\", \"tokens\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2108bf4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_fc = tweets_fc_df.withColumn(\"RT\", when(col(\"text\").startswith(\"RT\"), 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b664c9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- sentiment: string (nullable = false)\n",
      " |-- hourly_score: double (nullable = true)\n",
      " |-- count_score: long (nullable = false)\n",
      " |-- sum_RT: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----------+----+---------+--------------------+-----------+------+\n",
      "|year|month|day|      date|hour|sentiment|        hourly_score|count_score|sum_RT|\n",
      "+----+-----+---+----------+----+---------+--------------------+-----------+------+\n",
      "|2009|    4|  7|2009-04-07|   5|        0|-0.14324630610238717|         43|     0|\n",
      "|2009|    4|  7|2009-04-07|   5|        1| 0.34406590051663927|         49|     0|\n",
      "+----+-----+---+----------+----+---------+--------------------+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- hourly_score: double (nullable = true)\n",
      " |-- count_score: long (nullable = false)\n",
      " |-- sum_RT: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----------+----+-------------------+-----------+------+\n",
      "|year|month|day|      date|hour|       hourly_score|count_score|sum_RT|\n",
      "+----+-----+---+----------+----+-------------------+-----------+------+\n",
      "|2009|    4|  7|2009-04-07|   5|0.11630041264035516|         92|     0|\n",
      "|2009|    4|  7|2009-04-07|   6| 0.1477770113500622|        116|     0|\n",
      "+----+-----+---+----------+----+-------------------+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
    "\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, col, mean, count, to_date\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "\n",
    "\n",
    "tweets_hour = tweets_fc.groupBy(year(\"date\").alias(\"year\"), \n",
    "                               month(\"date\").alias(\"month\"),\n",
    "                               dayofmonth(\"date\").alias(\"day\"),\n",
    "                               to_date(col(\"date\")).alias(\"date\"),\n",
    "                               hour(\"date\").alias(\"hour\"),\n",
    "                               \"sentiment\") \\\n",
    "                      .agg(mean(col(\"score\")).alias(\"hourly_score\"),\n",
    "                           count(col(\"score\")).alias(\"count_score\"),\n",
    "                           spark_sum(col(\"RT\")).alias(\"sum_RT\"))\\\n",
    "                      .orderBy(\"year\", \"month\", \"day\", \"hour\")\n",
    "tweets_hour.printSchema()\n",
    "tweets_hour.show(2)\n",
    "\n",
    "tweets_hour_b = tweets_fc.groupBy(year(\"date\").alias(\"year\"), \n",
    "                               month(\"date\").alias(\"month\"),\n",
    "                               dayofmonth(\"date\").alias(\"day\"),\n",
    "                               to_date(col(\"date\")).alias(\"date\"),\n",
    "                               hour(\"date\").alias(\"hour\"),\n",
    "                               ) \\\n",
    "                      .agg(mean(col(\"score\")).alias(\"hourly_score\"),\n",
    "                           count(col(\"score\")).alias(\"count_score\"),\n",
    "                           spark_sum(col(\"RT\")).alias(\"sum_RT\"))\\\n",
    "                      .orderBy(\"year\", \"month\", \"day\", \"hour\")\n",
    "tweets_hour_b.printSchema()\n",
    "\n",
    "\n",
    "tweets_hour_b.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de30b505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of Tweets:100,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of 2,439 tweets per day (41 total)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "total_tweets = tweets_fc.count()\n",
    "print(f\"Total of Tweets:{total_tweets:,}\")\n",
    "\n",
    "days = tweets_fc.select(to_date(col(\"date\")).alias(\"data\")).agg(countDistinct(\"data\").alias(\"total_dias\")).first()[\"total_dias\"]\n",
    "mean_tweets = total_tweets / days\n",
    "print(f\"Average of {mean_tweets:,.0f} tweets per day ({days} total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85929a26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets_fc_pd = tweets_fc.withColumn(\"date\", date_format(\"date\", \"yyyy-MM-dd HH:mm:ss\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4df3666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(col, top_of, top_of_rename = None, sentiment = None, top_number = None, df = tweets_fc_pd):\n",
    "    \n",
    "    if sentiment == None:\n",
    "        df = pd.DataFrame(df[col].explode().dropna().tolist())\n",
    "    else: \n",
    "        df = pd.DataFrame(df[df.sentiment == sentiment][col].explode().dropna().tolist())\n",
    "        \n",
    "        \n",
    "    if top_number == None:\n",
    "        top = df[top_of].value_counts() \n",
    "    else:\n",
    "        top = df[top_of].value_counts().head(top_number)\n",
    "        \n",
    "    df = pd.DataFrame(top)\n",
    "    df.reset_index(drop = False, inplace=True)\n",
    "    df = df.rename(columns={top_of : top_of if top_of_rename == None else top_of_rename,\n",
    "                               'count': 'Value'})\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0947ffe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets_hour_pd = tweets_hour.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8c5c078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>hourly_score</th>\n",
       "      <th>count_score</th>\n",
       "      <th>sum_RT</th>\n",
       "      <th>min_hour</th>\n",
       "      <th>max_hour</th>\n",
       "      <th>hour_scaled</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.143246</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>134</td>\n",
       "      <td>0.283465</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.344066</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>181</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>6</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.126357</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>132</td>\n",
       "      <td>0.173469</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>6</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.362867</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>175</td>\n",
       "      <td>0.197080</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>7</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.334558</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>175</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>7</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.118805</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>131</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>8</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.109923</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>134</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>8</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.326535</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>188</td>\n",
       "      <td>0.337423</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>9</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.350315</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "      <td>0.417143</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>9</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.103772</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 09:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day        date  hour sentiment  hourly_score  count_score  \\\n",
       "0  2009      4    7  2009-04-07     5  Negative     -0.143246           43   \n",
       "1  2009      4    7  2009-04-07     5  Positive      0.344066           49   \n",
       "2  2009      4    7  2009-04-07     6  Negative     -0.126357           51   \n",
       "3  2009      4    7  2009-04-07     6  Positive      0.362867           65   \n",
       "4  2009      4    7  2009-04-07     7  Positive      0.334558           71   \n",
       "5  2009      4    7  2009-04-07     7  Negative     -0.118805           50   \n",
       "6  2009      4    7  2009-04-07     8  Negative     -0.109923           65   \n",
       "7  2009      4    7  2009-04-07     8  Positive      0.326535           80   \n",
       "8  2009      4    7  2009-04-07     9  Positive      0.350315           74   \n",
       "9  2009      4    7  2009-04-07     9  Negative     -0.103772           50   \n",
       "\n",
       "   sum_RT  min_hour  max_hour  hour_scaled day_of_week            datetime  \n",
       "0       0         7       134     0.283465     Tuesday 2009-04-07 05:00:00  \n",
       "1       0         4       181     0.254237     Tuesday 2009-04-07 05:00:00  \n",
       "2       0        34       132     0.173469     Tuesday 2009-04-07 06:00:00  \n",
       "3       0        38       175     0.197080     Tuesday 2009-04-07 06:00:00  \n",
       "4       0        29       175     0.287671     Tuesday 2009-04-07 07:00:00  \n",
       "5       0        41       131     0.100000     Tuesday 2009-04-07 07:00:00  \n",
       "6       0        38       134     0.281250     Tuesday 2009-04-07 08:00:00  \n",
       "7       0        25       188     0.337423     Tuesday 2009-04-07 08:00:00  \n",
       "8       0         1       176     0.417143     Tuesday 2009-04-07 09:00:00  \n",
       "9       0         1       121     0.408333     Tuesday 2009-04-07 09:00:00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_scaled_EDA = tweets_hour_pd.copy()\n",
    "\n",
    "# min max value calculation\n",
    "dataset_scaled_EDA['min_hour'] = dataset_scaled_EDA.groupby(['hour','sentiment'])[['count_score']] \\\n",
    "                                    .transform(lambda x: x.min())\n",
    "dataset_scaled_EDA['max_hour'] = dataset_scaled_EDA.groupby(['hour','sentiment'])[['count_score']] \\\n",
    "                                    .transform(lambda x: x.max())\n",
    "\n",
    "# scale\n",
    "dataset_scaled_EDA['hour_scaled'] = (dataset_scaled_EDA['count_score'] - dataset_scaled_EDA['min_hour'])/(dataset_scaled_EDA['max_hour'] - dataset_scaled_EDA['min_hour'])\n",
    "\n",
    "# add info about year, week of year and day of week\n",
    "dataset_scaled_EDA['day_of_week'] = [d.strftime('%A') for d in dataset_scaled_EDA['date']]\n",
    "dataset_scaled_EDA['day_of_week'] = pd.Categorical(dataset_scaled_EDA['day_of_week'], \n",
    "  categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "  ordered=True)\n",
    "\n",
    "#time with hour\n",
    "dataset_scaled_EDA['datetime'] = pd.to_datetime(dataset_scaled_EDA['date'].astype(str) + ' ' + \n",
    "                                                pd.to_datetime(dataset_scaled_EDA['hour'], format='%H')\\\n",
    "                                                .dt.time.astype(str), format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "dataset_scaled_EDA['sentiment'] = dataset_scaled_EDA['sentiment'].apply(lambda x: 'Positive' if x == '1' else 'Negative')\n",
    "dataset_scaled_EDA.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e24bb0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>hourly_score</th>\n",
       "      <th>count_score</th>\n",
       "      <th>sum_RT</th>\n",
       "      <th>min_hour</th>\n",
       "      <th>max_hour</th>\n",
       "      <th>hour_scaled</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>datetime</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>315</td>\n",
       "      <td>0.266447</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 05:00:00</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>6</td>\n",
       "      <td>0.147777</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>295</td>\n",
       "      <td>0.193694</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 06:00:00</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>7</td>\n",
       "      <td>0.147218</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>295</td>\n",
       "      <td>0.179245</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 07:00:00</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>8</td>\n",
       "      <td>0.130881</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>313</td>\n",
       "      <td>0.291139</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 08:00:00</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>9</td>\n",
       "      <td>0.167216</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>295</td>\n",
       "      <td>0.416382</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 09:00:00</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>10</td>\n",
       "      <td>0.135434</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>333</td>\n",
       "      <td>0.234657</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 10:00:00</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>11</td>\n",
       "      <td>0.164954</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>333</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 11:00:00</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>12</td>\n",
       "      <td>0.084601</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>320</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 12:00:00</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>13</td>\n",
       "      <td>0.162243</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>333</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 13:00:00</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>14</td>\n",
       "      <td>0.133470</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>320</td>\n",
       "      <td>0.231061</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2009-04-07 14:00:00</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day        date  hour  hourly_score  count_score  sum_RT  \\\n",
       "0  2009      4    7  2009-04-07     5      0.116300           92       0   \n",
       "1  2009      4    7  2009-04-07     6      0.147777          116       0   \n",
       "2  2009      4    7  2009-04-07     7      0.147218          121       0   \n",
       "3  2009      4    7  2009-04-07     8      0.130881          145       0   \n",
       "4  2009      4    7  2009-04-07     9      0.167216          124       0   \n",
       "5  2009      4    7  2009-04-07    10      0.135434          121       0   \n",
       "6  2009      4    7  2009-04-07    11      0.164954          135       0   \n",
       "7  2009      4    7  2009-04-07    12      0.084601          104       0   \n",
       "8  2009      4    7  2009-04-07    13      0.162243          124       0   \n",
       "9  2009      4    7  2009-04-07    14      0.133470          117       0   \n",
       "\n",
       "   min_hour  max_hour  hour_scaled day_of_week            datetime sentiment  \n",
       "0        11       315     0.266447     Tuesday 2009-04-07 05:00:00  Positive  \n",
       "1        73       295     0.193694     Tuesday 2009-04-07 06:00:00  Positive  \n",
       "2        83       295     0.179245     Tuesday 2009-04-07 07:00:00  Positive  \n",
       "3        76       313     0.291139     Tuesday 2009-04-07 08:00:00  Positive  \n",
       "4         2       295     0.416382     Tuesday 2009-04-07 09:00:00  Positive  \n",
       "5        56       333     0.234657     Tuesday 2009-04-07 10:00:00  Positive  \n",
       "6        39       333     0.326531     Tuesday 2009-04-07 11:00:00  Positive  \n",
       "7        95       320     0.040000     Tuesday 2009-04-07 12:00:00  Positive  \n",
       "8        14       333     0.344828     Tuesday 2009-04-07 13:00:00  Positive  \n",
       "9        56       320     0.231061     Tuesday 2009-04-07 14:00:00  Positive  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_hour_pd_b = tweets_hour_b.toPandas()\n",
    "\n",
    "# min max value calculation\n",
    "tweets_hour_pd_b['min_hour'] = tweets_hour_pd_b.groupby(['hour'])[['count_score']] \\\n",
    "                                    .transform(lambda x: x.min())\n",
    "tweets_hour_pd_b['max_hour'] = tweets_hour_pd_b.groupby(['hour'])[['count_score']] \\\n",
    "                                    .transform(lambda x: x.max())\n",
    "\n",
    "# scale\n",
    "tweets_hour_pd_b['hour_scaled'] = (tweets_hour_pd_b['count_score'] - tweets_hour_pd_b['min_hour'])/(tweets_hour_pd_b['max_hour'] - tweets_hour_pd_b['min_hour'])\n",
    "\n",
    "# add info about year, week of year and day of week\n",
    "tweets_hour_pd_b['day_of_week'] = [d.strftime('%A') for d in tweets_hour_pd_b['date']]\n",
    "tweets_hour_pd_b['day_of_week'] = pd.Categorical(tweets_hour_pd_b['day_of_week'], \n",
    "  categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "  ordered=True)\n",
    "\n",
    "#time with hour\n",
    "tweets_hour_pd_b['datetime'] = pd.to_datetime(tweets_hour_pd_b['date'].astype(str) + ' ' + \n",
    "                                                pd.to_datetime(tweets_hour_pd_b['hour'], format='%H')\\\n",
    "                                                .dt.time.astype(str), format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "tweets_hour_pd_b['sentiment'] = tweets_hour_pd_b['hourly_score'].apply(lambda x: 'Positive' if x > 0 else 'Negative' if x < 0 else 'Neutral')\n",
    "\n",
    "tweets_hour_pd_b.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab5a7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_scaled_EDA.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2e4301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dash\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash_bootstrap_templates import load_figure_template\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from dash.dependencies import Input,Output\n",
    "from dash import callback_context, Dash, html, dcc, Input, Output, dash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fca8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_figure_template('minty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21ff34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = dbc.Row(\n",
    "    [\n",
    "        dbc.Col(\n",
    "                dbc.CardImg(src=\"/assets/images/CCT_Logo.jpeg\", className=\"img-fluid rounded-start\"),\n",
    "            width={\"size\": 3},\n",
    "        ),\n",
    "        dbc.Col(\n",
    "            [\n",
    "                html.Div(\n",
    "                    [\n",
    "                        html.P(\"Twitter Analytics for\", className=\"card-title mx-auto\"),\n",
    "                        html.H1(\"Humans Feelings\", className=\"text-primary mx-auto\"),\n",
    "                    ]\n",
    "                )\n",
    "            ],\n",
    "            width={\"size\": 3, \"offset\": 3},\n",
    "            align=\"center\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6564aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CARD WITH TIMELINE -------------------------------------------------------------------------------------------------\n",
    "timeline = dbc.Card(\n",
    "    dbc.CardBody(\n",
    "        [\n",
    "            dbc.CardHeader(\n",
    "                html.H2(\"Timeline\", className=\"text-primary text-start card-title-large align-middle\"),\n",
    "            ),\n",
    "            \n",
    "            dcc.Graph(\n",
    "                id='timeline-plot',\n",
    "                figure=px.line(dataset_scaled_EDA, \n",
    "                               x='date', \n",
    "                               y='count_score',\n",
    "                               labels={\"date\": \"Date\", \n",
    "                                       \"count_score\": \"Total of Tweets\"},\n",
    "                              ),style={'height': '350px'}\n",
    "            ),\n",
    "        ],\n",
    "     ),\n",
    "    className=\"shadow my-2 text-center m-2\",\n",
    "    style={'margin': '0 auto'},\n",
    "    color=\"primary\", \n",
    "    outline=True ,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e11e82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "tweets_fc_pd['date'] = pd.to_datetime(tweets_fc_pd['date'])\n",
    "tweets_fc_pd['sentiment'] = tweets_fc_pd['sentiment'].astype(int)\n",
    "\n",
    "#COUNT STATICS -------------------------------------------------------------------------------------------------\n",
    "#avg_tweets_day = mean_tweets\n",
    "\n",
    "total_7 = tweets_fc_pd[(tweets_fc_pd['date'] >= pd.to_datetime(tweets_fc_pd['date'].max()) - timedelta(days=7))]['score'].count()\n",
    "total_30 = tweets_fc_pd[(tweets_fc_pd['date'] >= pd.to_datetime(tweets_fc_pd['date'].max()) - timedelta(days=30))]['score'].count()\n",
    "total_60 = tweets_fc_pd[(tweets_fc_pd['date'] >= pd.to_datetime(tweets_fc_pd['date'].max()) - timedelta(days=60))]['score'].count()\n",
    "\n",
    "mean_7 = tweets_fc_pd[(tweets_fc_pd['date'] >= pd.to_datetime(tweets_fc_pd['date'].max()) - timedelta(days=7))]['score'].count() / 7\n",
    "mean_30 = tweets_fc_pd[(tweets_fc_pd['date'] >= pd.to_datetime(tweets_fc_pd['date'].max()) - timedelta(days=30))]['score'].count() / 30\n",
    "mean_60 = tweets_fc_pd[(tweets_fc_pd['date'] >= pd.to_datetime(tweets_fc_pd['date'].max()) - timedelta(days=60))]['score'].count() / 60\n",
    "\n",
    "text_7 = f'{total_7:,.0f} ({mean_7:,.2f} per day)'\n",
    "text_30 = f'{total_30:,.0f} ({mean_30:,.2f} per day)'\n",
    "text_60 = f'{total_60:,.0f} ({mean_60:,.2f} per day)'\n",
    "\n",
    "\n",
    "#CARD WITH STATICS -------------------------------------------------------------------------------------------------\n",
    "stat_data = dbc.CardBody([\n",
    "    dbc.Row([dbc.Row(dbc.Col(html.H5(\"Av. Tweets: \", className=\"float-start\"))),\n",
    "             dbc.Row(dbc.Col(html.P(['{:,.0f}'.format(mean_tweets),' per day'], className=\"text-primary float-end\")))\n",
    "    ]),\n",
    "    \n",
    "    html.Div([\n",
    "        dbc.Row(dbc.Row(dbc.Col(html.H5(\"Historical Data\", className=\"text-center text-black w-100\")))),\n",
    "\n",
    "        dbc.Row([dbc.Row(dbc.Col(html.H6(\"Last 7 days: \", className=\"float-start m-1\"))),\n",
    "                 dbc.Row(dbc.Col(html.P(text_7, className=\"float-end text-primary\")))        \n",
    "        ]),\n",
    "\n",
    "        dbc.Row([dbc.Row(dbc.Col(html.H6(\"Last 30 days: \", className=\"float-start m-1\"))),\n",
    "                 dbc.Row(dbc.Col(html.P(text_30, className=\"float-end text-primary\")))        \n",
    "        ]),\n",
    "\n",
    "        dbc.Row([dbc.Row(dbc.Col(html.H6(\"Last 60 days: \", className=\"float-start m-1\"))),\n",
    "                 dbc.Row(dbc.Col(html.P(text_60, className=\"float-end text-primary\")))        \n",
    "        ]),\n",
    "    ], className=\"bg-light bg-gradient border rounded-top\")\n",
    "\n",
    " ],style={'height': '350px'})\n",
    "\n",
    "\n",
    "#CARD WITH STATICS -------------------------------------------------------------------------------------------------\n",
    "statics = dbc.Card(\n",
    "    dbc.CardBody(\n",
    "        [\n",
    "            dbc.CardHeader(\n",
    "            html.H2(\"Statistic\", className=\"text-primary text-center card-title-large align-middle\"),\n",
    "            ),\n",
    "            stat_data\n",
    "        ]\n",
    "     ),\n",
    "    className=\"shadow my-2 m-2\",\n",
    "    style={'margin': '0 auto'},\n",
    "    color=\"primary\", \n",
    "    outline=True ,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "017dd4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = tweets_hour_pd_b['hourly_score'].max()\n",
    "min_score = tweets_hour_pd_b['hourly_score'].min()\n",
    "min_date = tweets_hour_pd_b['datetime'].min()\n",
    "\n",
    "graf_3_1 = dbc.Card(\n",
    "            dbc.CardBody(\n",
    "                [\n",
    "                    dbc.CardHeader(\n",
    "                            html.H2(\"Tweet Timeline - Sentiment\",\n",
    "                                    className=\"text-primary text-start card-title-large align-middle\")\n",
    "                    ),\n",
    "                    dcc.Graph(\n",
    "                        id='tweet-timeline-plot-2',\n",
    "                        figure=px.scatter(\n",
    "                            tweets_hour_pd_b,\n",
    "                            x=\"datetime\",\n",
    "                            y=\"hourly_score\",\n",
    "                            size=\"count_score\",\n",
    "                            color=\"sentiment\",\n",
    "                            size_max=60,\n",
    "                            labels={\"datetime\": \"Date\", \"count_score\": \"Count Scaled\"}\n",
    "                        )\\\n",
    "                        # Y axes--------------------------------------------------------------------------------------\n",
    "                        .update_yaxes(visible=False,\n",
    "                                       showticklabels=False,\n",
    "                                       zeroline=True\n",
    "                        )\\\n",
    "                        # Max score Line------------------------------------------------------------------------------\n",
    "                        .add_hline(y=max_score, \n",
    "                              line_width=0.1, \n",
    "                              #line_dash=\"dash\", \n",
    "                              line_color=\"gray\"\n",
    "                        )\\\n",
    "                        # Min Score Line------------------------------------------------------------------------------\n",
    "                        .add_hline(y=min_score, \n",
    "                              line_width=0.1, \n",
    "                              #line_dash=\"dash\", \n",
    "                              line_color=\"gray\"\n",
    "                        )\\\n",
    "                        # Neutral Score Line--------------------------------------------------------------------------\n",
    "                        .add_hline(y=0, \n",
    "                              line_width=0.1, \n",
    "                              #line_dash=\"dash\", \n",
    "                              line_color=\"gray\"\n",
    "                        )\\\n",
    "                        # Max Score Annotation------------------------------------------------------------------------\n",
    "                        .add_annotation(x= min_date, \n",
    "                               y=max_score,\n",
    "                               text= f\"<b> Most Positive </b> <br>{max_score:,.2f}\",\n",
    "                               #showarrow=True,\n",
    "                               #arrowhead=2,\n",
    "                               ax= -40,\n",
    "                               ay= 0,\n",
    "                               opacity=0.7,\n",
    "                               #xshift=55,\n",
    "                               arrowcolor=\"#41b6c4\"\n",
    "                        )\\\n",
    "                        # Min Score Annotation------------------------------------------------------------------------\n",
    "                        .add_annotation(x= min_date, \n",
    "                               y=min_score,\n",
    "                               text= f\"<b> Most Negative </b> <br>{min_score:,.2f}\",\n",
    "                               #showarrow=True,\n",
    "                               #arrowhead=2,\n",
    "                               ax= -40,\n",
    "                               ay= 0,\n",
    "                               opacity=0.7,\n",
    "                               #xshift=55,\n",
    "                               arrowcolor=\"#41b6c4\"\n",
    "                        )\\\n",
    "                        # Neutral Score Annotation--------------------------------------------------------------------\n",
    "                        .add_annotation(x= min_date, \n",
    "                               y=0,\n",
    "                               text= f\"<b> Neutral</b> <br> 0.00\",\n",
    "                               #showarrow=True,\n",
    "                               #arrowhead=2,\n",
    "                               ax= -40,\n",
    "                               ay= 0,\n",
    "                               opacity=0.7,\n",
    "                               #xshift=55,\n",
    "                               arrowcolor=\"#41b6c4\"\n",
    "                        )\\\n",
    "                        # Adjust Legend-------------------------------------------------------------------------------\n",
    "                        .update_layout(\n",
    "                                legend=dict(\n",
    "                                    x=1,\n",
    "                                    y=1,\n",
    "                                    xanchor='right',\n",
    "                                    yanchor='top'\n",
    "                                )\n",
    "                            ),\n",
    "\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "    className=\"shadow my-2 text-center m-1\",\n",
    "    style={'margin': '0 auto'},\n",
    "    color=\"primary\", \n",
    "    outline=True ,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50ec4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_total = tweets_fc_pd['sentiment'].sum() / total_tweets\n",
    "perc_pos_7 = tweets_fc_pd[(tweets_fc_pd['date'] >= pd.to_datetime(tweets_fc_pd['date'].max()) - timedelta(days=7))]['sentiment'].sum() / total_7\n",
    "perc_pos_30 = tweets_fc_pd[(tweets_fc_pd['date'] >= pd.to_datetime(tweets_fc_pd['date'].max()) - timedelta(days=30))]['sentiment'].sum() / total_30\n",
    "perc_pos_60 = tweets_fc_pd[(tweets_fc_pd['date'] >= pd.to_datetime(tweets_fc_pd['date'].max()) - timedelta(days=60))]['sentiment'].sum() / total_60\n",
    "data = {\n",
    "    'period' : ['7 days', '7 days', '30 days', '30 days', '60 days', '60 days', 'Total', 'Total'],\n",
    "    'sentiment' : ['Positive', 'Negative','Positive', 'Negative','Positive', 'Negative','Positive', 'Negative'],\n",
    "    'value': [perc_pos_7, (1-perc_pos_7), perc_pos_30, (1-perc_pos_30), perc_pos_60, (1-perc_pos_60), perc_total, (1-perc_total)]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "colors = {'Positive': 'blue', 'Negative': 'rgba(128, 128, 128, 0.1)'}\n",
    "\n",
    "\n",
    "graf_stat = dbc.Card(\n",
    "            dbc.CardBody(\n",
    "                [\n",
    "                    dbc.CardHeader(\n",
    "                            html.H2(\"Statistics\",\n",
    "                                    className=\"text-primary text-center card-title-large align-middle\")\n",
    "                    ),\n",
    "                    dcc.Graph(\n",
    "                        id='tweet-sentiment',\n",
    "                        figure = px.bar(df, x='value', y='period', color='sentiment', orientation='h',\n",
    "                                     color_discrete_map=colors,\n",
    "                                     labels={'value': '', 'period': '', 'sentiment': ''})\\\n",
    "                        \n",
    "                        # Adjust Legend-------------------------------------------------------------------------------\n",
    "                        .update_layout(\n",
    "                            showlegend=False, \n",
    "                            xaxis_showticklabels=False,\n",
    "                            yaxis_showticklabels=False, \n",
    "                            xaxis_range=[0, 1],\n",
    "                            #margin=dict(l=100, r=100, t=100, b=100), \n",
    "                            uniformtext_minsize=8, \n",
    "                            bargap=0.95,  \n",
    "                            xaxis=dict(showticklabels=False, showgrid=False), \n",
    "                            yaxis=dict(showticklabels=False, showgrid=False)  \n",
    "                        )\\\n",
    "                        \n",
    "                        # Adjust Legend---------------------------------TOTAL----------------------------------------------\n",
    "                        .add_annotation(x= 0.2, \n",
    "                               y='Total',\n",
    "                               text= f\"Total\",\n",
    "                               #showarrow=True,\n",
    "                               #arrowhead=2,\n",
    "                               ax= 0,\n",
    "                               ay= 0,\n",
    "                               opacity=1,\n",
    "                               xshift=-50,\n",
    "                               yshift=17,\n",
    "                               arrowcolor=\"#41b6c4\",\n",
    "                               font=dict(size=24)\n",
    "                    )\\\n",
    "                        \n",
    "                        # Adjust Legend-------------------------------------------------------------------------------\n",
    "                        .add_annotation(x= 1, \n",
    "                               y='Total',\n",
    "                               text= f\"{perc_total:,.2%}\",\n",
    "                               #showarrow=True,\n",
    "                               #arrowhead=6,\n",
    "                               ax= 10,\n",
    "                               ay= -13,\n",
    "                               opacity=1,\n",
    "                               #xshift=0,\n",
    "                               #yshift=-17,\n",
    "                               #arrowcolor=\"#333333\",\n",
    "                               font=dict(size=16)\n",
    "                    )\\\n",
    "                        \n",
    "                        # Adjust Legend---------------------------------7 DAYS----------------------------------------------\n",
    "                        .add_annotation(x= 0.2, \n",
    "                               y='7 days',\n",
    "                               text= f\"7 Days\",\n",
    "                               #showarrow=True,\n",
    "                               #arrowhead=2,\n",
    "                               ax= 0,\n",
    "                               ay= 0,\n",
    "                               opacity=1,\n",
    "                               xshift=-60,\n",
    "                               yshift=17,\n",
    "                               arrowcolor=\"#41b6c4\",\n",
    "                               font=dict(size=24)\n",
    "                    )\\\n",
    "                        \n",
    "                        # Adjust Legend-------------------------------------------------------------------------------\n",
    "                        .add_annotation(x= 1, \n",
    "                               y='7 days',\n",
    "                               text= f\"{perc_pos_7:,.2%}\",\n",
    "                               #showarrow=True,\n",
    "                               #arrowhead=6,\n",
    "                               ax= 10,\n",
    "                               ay= -13,\n",
    "                               opacity=1,\n",
    "                               #xshift=0,\n",
    "                               #yshift=-17,\n",
    "                               #arrowcolor=\"#333333\",\n",
    "                               font=dict(size=16)\n",
    "                    )\\\n",
    "                        \n",
    "                        # Adjust Legend----------------------------------30 DAYS---------------------------------------------\n",
    "                        .add_annotation(x= 0.2, \n",
    "                               y='30 days',\n",
    "                               text= \"30 Days\",\n",
    "                               #showarrow=True,\n",
    "                               #arrowhead=2,\n",
    "                               ax= 0,\n",
    "                               ay= 0,\n",
    "                               opacity=1,\n",
    "                               xshift=-65,\n",
    "                               yshift=17,\n",
    "                               arrowcolor=\"#41b6c4\",\n",
    "                               font=dict(size=24)\n",
    "                    )\\\n",
    "                        \n",
    "                        # Adjust Legend-------------------------------------------------------------------------------\n",
    "                        .add_annotation(x= 1, \n",
    "                               y='30 days',\n",
    "                               text= f\"{perc_pos_30:,.2%}\",\n",
    "                               #showarrow=True,\n",
    "                               #arrowhead=6,\n",
    "                               ax= 10,\n",
    "                               ay= -13,\n",
    "                               opacity=1,\n",
    "                               #xshift=0,\n",
    "                               #yshift=-17,\n",
    "                               #arrowcolor=\"#333333\",\n",
    "                               font=dict(size=16)\n",
    "                    )\\\n",
    "                        \n",
    "                        # Adjust Legend-----------------------------------60 DAYS--------------------------------------------\n",
    "                        .add_annotation(x= 0.2, \n",
    "                               y='60 days',\n",
    "                               text= \"60 Days\",\n",
    "                               #showarrow=True,\n",
    "                               #arrowhead=2,\n",
    "                               ax= 0,\n",
    "                               ay= 0,\n",
    "                               opacity=1,\n",
    "                               xshift=-65,\n",
    "                               yshift=17,\n",
    "                               arrowcolor=\"#41b6c4\",\n",
    "                               font=dict(size=24)\n",
    "                    )\\\n",
    "                        \n",
    "                        # Adjust Legend-------------------------------------------------------------------------------\n",
    "                        .add_annotation(x= 1, \n",
    "                               y='60 days',\n",
    "                               text= f\"{perc_pos_60:,.2%}\",\n",
    "                               #showarrow=True,\n",
    "                               #arrowhead=6,\n",
    "                               ax= 10,\n",
    "                               ay= -13,\n",
    "                               opacity=1,\n",
    "                               #xshift=0,\n",
    "                               #yshift=-17,\n",
    "                               #arrowcolor=\"#333333\",\n",
    "                               font=dict(size=16)\n",
    "                    )\n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        ,style={'width': '100%', 'height': '100%'}\n",
    "                )\n",
    "                ]\n",
    "            ),className=\"shadow my-2 text-center m-1\",\n",
    "            style={'margin': '0 auto'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d50a2d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7e6292cc40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "app = JupyterDash(external_stylesheets=[dbc.themes.MINTY, dbc.icons.BOOTSTRAP], )\n",
    "\n",
    "    \n",
    "app.layout = dbc.Container([\n",
    "    \n",
    "#TITLE---------------------------------------------------------------------------------------------------------------\n",
    "    dbc.Row([\n",
    "        dbc.Col(title, width = 12),\n",
    "    ],\n",
    "    ),\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#ROW 2----------------------------------------------------------------------------------------------------------------\n",
    "    dbc.Row([\n",
    "        dbc.Col(timeline, width = 8),\n",
    "        dbc.Col(statics, width = 4),\n",
    "    ],style={'margin': '0 auto'}\n",
    "    ),\n",
    "    \n",
    "#ROW 3----------------------------------------------------------------------------------------------------------------\n",
    "    dbc.Row([\n",
    "        dbc.Col(graf_3_1, width = 8),\n",
    "        dbc.Col(graf_stat, width = 4),\n",
    "    ],style={'margin': '0 auto'}\n",
    "    ),\n",
    "    \n",
    "#ROW 4----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "     \n",
    "    \n",
    "\n",
    "#END------------------------------------------------------------------------------------------------------------------\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "def update_tables(active_tab):\n",
    "    if active_tab == 'tab-1':\n",
    "        user_table_data = user_tables_pos.to_dict('records')\n",
    "        urls_table_data = urls_tables_pos.to_dict('records')\n",
    "        src_hashtag = 'assets/images/hashtags_pos.png'\n",
    "        fig_emoji = px.bar(emojis_pos, y='Emoji', x='Frequency', orientation='h')\n",
    "        fig_emoji.update_layout(yaxis_tickfont=dict(size=12), yaxis=dict(autorange=\"reversed\"))\n",
    "        \n",
    "    else:\n",
    "        user_table_data = user_tables_neg.to_dict('records')\n",
    "        urls_table_data = urls_tables_neg.to_dict('records')\n",
    "        src_hashtag = 'assets/images/hashtags_neg.png'\n",
    "        fig_emoji = px.bar(emojis_neg, y='Emoji', x='Frequency', orientation='h')\n",
    "        fig_emoji.update_layout(yaxis_tickfont=dict(size=12), yaxis=dict(autorange=\"reversed\"))\n",
    "\n",
    "    return user_table_data, urls_table_data, src_hashtag, fig_emoji\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True)#mode='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1a129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eefc4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
